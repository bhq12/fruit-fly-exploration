{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RtpIC9fDJAM"
   },
   "source": [
    "# Prac W8\n",
    "## MLPS and Convolutional Neural Networks (CNNs) using Tensorflow 2.x\n",
    "\n",
    "A lot of this will be borrowed from the Tensorflow introduction found [here](https://www.tensorflow.org/tutorials/)\n",
    "\n",
    "You've already covered multilayer perceptrons in last weeks prac. CNNs are possibly part of the reason you're interested in this course due to their strengths in image classification.\n",
    "\n",
    "[This link](https://cs231n.github.io/convolutional-networks/) provides a good overview of CNNs and would be useful to read. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyAHHQ7dEmH7"
   },
   "source": [
    "Some useful imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PW-AQDwnC9TT",
    "outputId": "fd62b44b-69ec-4ea2-da09-1bef21f11b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "%load_ext tensorboard\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Conv3D, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "import datetime\n",
    "import numpy as np\n",
    "!rm -rf ./logs/ \n",
    "print(tf.__version__) #Double check the colab has the instance of tensorflow we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "RKKn1Vq9PG19"
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR10 dataset\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "(cifar_x_train, cifar_y_train), (cifar_x_test, cifar_y_test) = cifar10.load_data()\n",
    "\n",
    "cifar_x_train = cifar_x_train / 255\n",
    "cifar_x_test = cifar_x_test / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image count:\n",
      "50000\n",
      "Pixels dimension 1:\n",
      "32\n",
      "Pixels dimension 2:\n",
      "32\n",
      "RGB Dimensions:\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"Image count:\")\n",
    "print(len(cifar_x_train))\n",
    "print(\"Pixels dimension 1:\")\n",
    "print(len(cifar_x_train[0]))\n",
    "print(\"Pixels dimension 2:\")\n",
    "print(len(cifar_x_train[0][0]))\n",
    "print(\"RGB Dimensions:\")\n",
    "print(len(cifar_x_train[0][0][0]))\n",
    "\n",
    "\n",
    "#cifar_x_train = cifar_x_train.astype(np.float32)\n",
    "#cifar_x_test = cifar_x_test.astype(np.float32)\n",
    "\n",
    "cifar_train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (cifar_x_train, cifar_y_train)\n",
    ").shuffle(10000).batch(32)\n",
    "\n",
    "cifar_test_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (cifar_x_test, cifar_y_test)\n",
    ").batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "  def __init__(\n",
    "      self,\n",
    "      model_name,\n",
    "      model, \n",
    "      optimiser = tf.keras.optimizers.Adam(),\n",
    "      loss_object=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "  ):\n",
    "    self._model = model\n",
    "    self.model_name = model_name\n",
    "    self._optimiser = optimiser \n",
    "    self._loss_object = loss_object\n",
    "    self._train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    self._train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "    self._test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    self._test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "  \n",
    "  @tf.function\n",
    "  def train_step(self, images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "      # training=True is only needed if there are layers with different\n",
    "      # behavior during training versus inference (e.g. Dropout).\n",
    "      predictions = self._model(images, training=True)\n",
    "      loss = self._loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, self._model.trainable_variables)\n",
    "    self._optimiser.apply_gradients(zip(gradients, self._model.trainable_variables))\n",
    "\n",
    "    self._train_loss(loss)\n",
    "    self._train_accuracy(labels, predictions) \n",
    "\n",
    "  @tf.function\n",
    "  def test_step(self, images, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = self._model(images, training=False)\n",
    "    t_loss = self._loss_object(labels, predictions)\n",
    "\n",
    "    self._test_loss(t_loss)\n",
    "    self._test_accuracy(labels, predictions)\n",
    "\n",
    "  def train(self, train_ds, test_ds, epochs):\n",
    "    for epoch in range(epochs):\n",
    "      # Reset the metrics at the start of the next epoch\n",
    "      self._train_loss.reset_state()\n",
    "      self._train_accuracy.reset_state()\n",
    "      self._test_loss.reset_state()\n",
    "      self._test_accuracy.reset_state()\n",
    "\n",
    "      for images, labels in train_ds:\n",
    "        self.train_step(images, labels)\n",
    "\n",
    "      for test_images, test_labels in test_ds:\n",
    "        self.test_step(test_images, test_labels)\n",
    "\n",
    "      template = 'Model: {}, Epoch: {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "      print(template.format(\n",
    "        self.model_name,\n",
    "        epoch + 1,\n",
    "        self._train_loss.result(),\n",
    "        self._train_accuracy.result() * 100,\n",
    "        self._test_loss.result(),\n",
    "        self._test_accuracy.result() * 100)\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGTYF2lJPBfE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - accuracy: 0.3559 - loss: 2.0827 - val_accuracy: 0.4644 - val_loss: 1.5101\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.4880 - loss: 1.4573 - val_accuracy: 0.4815 - val_loss: 1.4775\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5341 - loss: 1.3258 - val_accuracy: 0.5000 - val_loss: 1.4325\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 37ms/step - accuracy: 0.5757 - loss: 1.2113 - val_accuracy: 0.5017 - val_loss: 1.4589\n",
      "Epoch 5/5\n",
      "\u001b[1m 838/1563\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 35ms/step - accuracy: 0.6148 - loss: 1.1026"
     ]
    }
   ],
   "source": [
    "model =  tf.keras.models.Sequential([\n",
    "            Conv2D(32,(3,3)), \n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "          ])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") #datetime storage\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1) #TB callbacks\n",
    "\n",
    "#model.fit(cifar_train_ds, epochs=5, validation_data=cifar_test_ds, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "testers = []\n",
    "\n",
    "model_single_convolutional_layer =  tf.keras.models.Sequential([\n",
    "            Conv2D(32,3),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "          ])\n",
    "\n",
    "tester_convolutional_layer = ModelTester('Single Convolution layer', model_single_convolutional_layer)\n",
    "testers.append(tester_convolutional_layer)\n",
    "\n",
    "model_single_convolutional_layer_no_softmax =  tf.keras.models.Sequential([\n",
    "            Conv2D(32,3),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu')\n",
    "          ])\n",
    "\n",
    "tester_convolutional_layer_no_softmax = ModelTester('Single Convolution layer no softmax', model_single_convolutional_layer_no_softmax)\n",
    "testers.append(tester_convolutional_layer_no_softmax )\n",
    "\n",
    "\n",
    "model_two_convolutional_layers =  tf.keras.models.Sequential([\n",
    "            Conv2D(32,(3,3)), \n",
    "            Conv2D(32,(3,3)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "          ])\n",
    "\n",
    "tester_two_convolutional_layers = ModelTester('Two Convolution layers', model_two_convolutional_layers)\n",
    "testers.append(tester_two_convolutional_layers)\n",
    "\n",
    "model_single_convolutional_layer_multiple_dense_layers =  tf.keras.models.Sequential([\n",
    "            Conv2D(32,3),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "          ])\n",
    "\n",
    "tester_convolutional_layer_multiple_dense = ModelTester('Single Convolution layer multiple dense layers', model_single_convolutional_layer_multiple_dense_layers)\n",
    "testers.append(tester_convolutional_layer_multiple_dense)\n",
    "\n",
    "\n",
    "model_single_convolutional_layer_multiple_small_dense_layers =  tf.keras.models.Sequential([\n",
    "            Conv2D(32,3),\n",
    "            Flatten(),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(10, activation='softmax')\n",
    "          ])\n",
    "\n",
    "tester_convolutional_layer_multiple_small_dense = ModelTester('Single Convolution layer many small dense layers', model_single_convolutional_layer_multiple_small_dense_layers)\n",
    "testers.append(tester_convolutional_layer_multiple_small_dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/var/folders/j_/9f1md2vd0_s6kpn12szf1t2c0000gn/T/ipykernel_43252/442613238.py\", line 27, in train_step  *\n        self._optimiser.apply_gradients(zip(gradients, self._model.trainable_variables))\n    File \"/Users/brookqueree/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 279, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/Users/brookqueree/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 320, in apply\n        self._check_variables_are_known(trainable_variables)\n    File \"/Users/brookqueree/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 225, in _check_variables_are_known\n        raise ValueError(\n\n    ValueError: Unknown variable: <KerasVariable shape=(3, 3, 3, 32), dtype=float32, path=sequential_37/conv2d_35/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tester \u001b[38;5;129;01min\u001b[39;00m testers:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcifar_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcifar_test_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 51\u001b[0m, in \u001b[0;36mModelTester.train\u001b[0;34m(self, train_ds, test_ds, epochs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_test_accuracy\u001b[38;5;241m.\u001b[39mreset_state()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_ds:\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_images, test_labels \u001b[38;5;129;01min\u001b[39;00m test_ds:\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_step(test_images, test_labels)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/j_/9f1md2vd0_s6kpn12szf1t2c0000gn/T/__autograph_generated_fileia15wa4x.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_loss_object, (ag__\u001b[38;5;241m.\u001b[39mld(labels), ag__\u001b[38;5;241m.\u001b[39mld(predictions)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_train_loss, (ag__\u001b[38;5;241m.\u001b[39mld(loss),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_train_accuracy, (ag__\u001b[38;5;241m.\u001b[39mld(labels), ag__\u001b[38;5;241m.\u001b[39mld(predictions)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:279\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    278\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:320\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(trainable_variables)\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_variables_are_known\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# Filter empty gradients.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_empty_gradients(\n\u001b[1;32m    325\u001b[0m         grads, trainable_variables\n\u001b[1;32m    326\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:225\u001b[0m, in \u001b[0;36mBaseOptimizer._check_variables_are_known\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m variables:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_key(v) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_variables_indices:\n\u001b[0;32m--> 225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This optimizer can only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe called for the variables it was originally built with. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen working with a new set of variables, you should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecreate a new optimizer instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/var/folders/j_/9f1md2vd0_s6kpn12szf1t2c0000gn/T/ipykernel_43252/442613238.py\", line 27, in train_step  *\n        self._optimiser.apply_gradients(zip(gradients, self._model.trainable_variables))\n    File \"/Users/brookqueree/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 279, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/Users/brookqueree/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 320, in apply\n        self._check_variables_are_known(trainable_variables)\n    File \"/Users/brookqueree/Library/Caches/pypoetry/virtualenvs/comp3702_week3_practical-bNmBW1Wz-py3.12/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py\", line 225, in _check_variables_are_known\n        raise ValueError(\n\n    ValueError: Unknown variable: <KerasVariable shape=(3, 3, 3, 32), dtype=float32, path=sequential_37/conv2d_35/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n"
     ]
    }
   ],
   "source": [
    "for tester in testers:\n",
    "    tester.train(cifar_train_ds, cifar_test_ds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
